---
layout: post
category: "platform"
title: "美图的MML"
tags: [美图, MML, bamboo, ]
---

目录

<!-- TOC -->

- [概述](#概述)
- [召回+排序](#召回排序)
- [多目标](#多目标)
    - [样本reweight](#样本reweight)
    - [多目标模型](#多目标模型)
    - [多模型](#多模型)
    - [多个多目标模型](#多个多目标模型)

<!-- /TOC -->



## 概述

[当推荐遇到社交：美图的推荐算法设计优化实践](https://mp.weixin.qq.com/s/Eih4J51C8Eh-cuZ8vznESg)

MML 机器学习平台包括三个主要模块：

+ Spark Feature：负责数据分析、特征工程，以及样本拼接。Spark Feature 基于 Spark SQL 进行开发，用户通过编写 SQL 以及配置样本拼接 JSON，即可实现特征以及样本生产的工作；
+ Bamboo：基于 tensorflow 开发，负责模型训练、离线效果评估。Bamboo 实现了推荐领域大量的 State of the Art 的模型，并且提供了丰富的 Layers，以简化算法同学的建模工作。在训练方面支持多种并行训练方式，同时通过对代码的优化实现了较高的训练效率；
+ MML Serving：负责模型的在线服务。底层通过 C++ 实现，在内存和并发上做了大量的优化，支持同时请求多个模型，以及在线热更。灵活的架构让我们能够很方便地接入各种机器学习框架训练的模型。

Bamboo 具有以下优点：

+ 便捷：内置了近几年推荐领域的 SOTA 模型，以及建模常用的 Layers，并且内置了部分公共数据集的访问接口，能够支持从本地磁盘，以及 HDFS 读取训练数据。数据、训练、模型评估、模型导出通过配置化实现，算法同学可以专注于模型的设计；
+ 高效：采用 tensorflow 底层 API 和 Estimator 来实现，并遵循 tensorflow 官方性能优化指南，最大限度提升模型训练效率，相比 Keras 以及内部未优化版本，单卡训练效率有数倍提升。同时，能够支持同步、异步等多种并行训练方案；
+ 可扩展：Bamboo 的最初的设计目标是作为 tensorflow 的补充，因此在整个设计过程充分考虑了扩展性，能够支持采用 Bamboo 提供的 API 或者使用 tensorflow 原生 API。良好的分层设计，方便使用方进行模块的复用和重构。

MML Serving 决定了模型能否上线提供服务以及在线服务的效率。去年下半年，我们上线了采用 C++ 开发的新版 MML Serving，通过内存和并发的优化，让我们整体预估耗时减少了 50%，服务初始化耗时减少了 50%，内存使用量降低了 77%。通过压测发现，服务在高并发下，整体表现稳定。另外良好的架构设计，可以很方便接入各种第三方机器学习库，目前已经内置了对 tensorflow 和 xgboost 模型的支持。

2018 年，我们上线了第一个基于何向南在 SIGIR 2017 发表的《Neural Factorization Machines for Sparse Predictive Analytics》改进的模型——NFM-v4。相比原论文，我们的主要改进点是通过一个线性变换，将变长稀疏的原始高维特征压缩到一个定长稠密的低维实数空间，从而屏蔽了模型在输入特征处理上的差异，可以将精力更多放在特征的挖掘上。

但是，将几十万维的高维空间直接压缩到几百维，存在一定的信息损失，因此，在 NFM-v4 的基础上，我们通过将部分高维 id 特征单独建模，比较好的解决了这个问题，在业务指标上，也有不错的效果提升，美拍的人均播放时长增加了 4.75%，人均有效行为数增加了 3.45%。

不过，NFM 存在的一个问题是，bi-interaction pooling 认为特征二阶交叉的权重是相等的，这种假设在多数场景下并不符合数据的真实分布。因此，在 NFM 的基础上，我们提出了 Neural Field weighted Factorization Machines（NFwFM）模型，通过引入一个权重向量，来建模二阶交叉特征的权重。通过二阶向量不等权相加，业务指标整体提升较为明显。其中美拍人均播放时长增加 3.78%，播放用户数增加 1.74%，美图秀秀点击率提升了 5.689%，人均使用时长增加 2.53%，新用户点击率增加 2.701%。

目前，我们主要尝试了三种用户行为序列建模的方法，包括 Sum/Mean Pooling 、 RNN 、 Attention 等。在我们的业务场景下，

+ RNN 的离线效果并不理想，原因推测是用户点击 feed 的先后顺序并不存在某种固定的模式，而主要取决于用户对所推荐 feed 的偏好，此外，RNN 的训练耗时也增加比较明显。
+ Sum/Mean Pooling 的方式虽然简单，但是在长行为序列建模上，效果相比其它两种方式表现得更加优异，因此是我们目前线上建模用户长序列特征的主要手段。
+ 我们也对比了基于 Attention 的方法，离线效果相比 Sum/Mean Pooling 有略微提升，但是考虑到计算复杂度，Attention 只适合于序列长度较短的场景。

在美拍，美图秀秀社区，以及 push 业务都尝试了用户行为序列特征建模，各项业务指标均有较大幅度的提升，美拍人均时长提升了 12%，秀秀的点击率提升了 5%，push 的到达点击率提升了 10%。

## 召回+排序

[深度学习技术在美图个性化推荐的应用实践](https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247494558&idx=1&sn=10a6332147d713230d0fa4dbf9cdc897&chksm=fbd759f2cca0d0e4f5d39887a86b1d6efae13ad0540dc191fdbc8bb29120d0081a90c97b35f6&scene=27#wechat_redirect)

## 多目标

整个多目标优化的路线，大概经历了四个阶段：样本 reweight，多目标模型，多模型，多个多目标模型。


### 样本reweight

样本 reweight 是一种简单轻量的可用于解决多目标问题的做法，它借鉴了 imbalanced data 的典型做法，在保持模型优化的主目标不变的情况下，通过提高次要目标的正样本占比，来模拟多目标的联合概率分布。

我们在美拍和美图秀秀社区上，对增加关注目标进行了尝试。美拍在播放时长略微上涨的情况下，实现了人均关注 10.06% 的提升。美图秀秀社区关注转化率提升了 12.03%，不过点击率也有略微的下降。

样本 reweight 的方式改变了样本的原始分布，导致主目标存在比较大的预估偏差。同时，因为次要目标是通过主目标的网络结构来实现，无法对各个目标的模型分别进行调优，模型结构优化存在比较大的局限性。

### 多目标模型

多目标模型通过共享底层的网络输入，实现信息共享，再根据每个目标的数据特点，分别构建各个目标的输出网络，得到每个目标的输出。

在美图的多个社交场景中，我们进行了尝试，并取得了比较大的在线提升。其中，在美拍双列 feed 流场景下，人均关注提升 11.43%，人均播放时长提升 12.45%。美图秀秀首页 feed 流，点击率提升 1.93%，关注率提升 2.9%。美图秀秀下滑 feed 流，关注率提升 9.3%，人均时长提升 10.33%。

### 多模型

虽然多目标模型在业务上取得了比较大的提升，但是仍然存在一些问题。典型的问题包括：

+ 当不同任务的目标相关性较弱，或者损失函数的输出值范围差异较大时，多目标模型的调优存在比较大的困难；
+ 使用多目标模型，会导致不同目标的优化存在比较大的耦合，延迟整体优化进度，在产品要求快速迭代的场景下，这种技术手段不一定能够很好的满足业务需求。

为了解决多目标模型存在的一些问题，我们通过拆分多目标模型的各个目标，得到多个单目标模型，并对每个单目标模型分别进行优化。在美拍双列 feed 流场景下，我们进行了相应的尝试，在人均时长不变的情况下，人均关注提升了 2.98%。通过进一步调整模型的优化目标，人均时长再次提升了 19.37%，人均关注提升了 14.1%。

### 多个多目标模型

当推荐场景的优化目标增加，多模型的方案会存在维护成本高，线上资源开销大，各个任务的模型无法利用其它任务的数据等问题。

综合多模型和多目标模型的优点，采用多个多目标模型是解决多目标任务的有效手段。在美拍场景下，通过同时优化关注、时长、播放等目标，人均关注提升 12.18%，活跃留存提升 25.67%。
